{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "['_MutableMapping__marker', '__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__setattr__', '__setitem__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', 'clear', 'get', 'items', 'keys', 'pop', 'popitem', 'setdefault', 'to_dict', 'update', 'values']\n"
     ]
    }
   ],
   "source": [
    "print(st.session_state)\n",
    "# print all methods and attributes of st.session_state\n",
    "print(dir(st.session_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "st.session_state has no attribute \"hello\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\HONGYI001\\Anaconda3\\envs\\med-agent\\Lib\\site-packages\\streamlit\\runtime\\state\\session_state.py:411\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\HONGYI001\\Anaconda3\\envs\\med-agent\\Lib\\site-packages\\streamlit\\runtime\\state\\session_state.py:456\u001b[0m, in \u001b[0;36mSessionState._getitem\u001b[1;34m(self, widget_id, user_key)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\HONGYI001\\Anaconda3\\envs\\med-agent\\Lib\\site-packages\\streamlit\\runtime\\state\\session_state_proxy.py:127\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\HONGYI001\\Anaconda3\\envs\\med-agent\\Lib\\site-packages\\streamlit\\runtime\\state\\session_state_proxy.py:98\u001b[0m, in \u001b[0;36mSessionStateProxy.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     97\u001b[0m require_valid_user_key(key)\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_session_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HONGYI001\\Anaconda3\\envs\\med-agent\\Lib\\site-packages\\streamlit\\runtime\\state\\safe_session_state.py:93\u001b[0m, in \u001b[0;36mSafeSessionState.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HONGYI001\\Anaconda3\\envs\\med-agent\\Lib\\site-packages\\streamlit\\runtime\\state\\session_state.py:413\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[1;31mKeyError\u001b[0m: 'st.session_state has no key \"hello\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhello\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HONGYI001\\Anaconda3\\envs\\med-agent\\Lib\\site-packages\\streamlit\\runtime\\state\\session_state_proxy.py:129\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(_missing_attr_error_message(key))\n",
      "\u001b[1;31mAttributeError\u001b[0m: st.session_state has no attribute \"hello\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization"
     ]
    }
   ],
   "source": [
    "st.session_state.hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "llm = ChatOllama(model=\"codellama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\nI am LLaMA, an AI assistant developed by Meta AI that can understand and respond to human input in a conversational manner. I am trained on a massive dataset of text from the internet and can generate human-like responses to a wide range of topics and questions. I can be used to create chatbots, virtual assistants, and other applications that require natural language understanding and generation capabilities.', response_metadata={'model': 'codellama', 'created_at': '2024-06-06T08:19:37.5177758Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 1756874900, 'load_duration': 11467600, 'prompt_eval_count': 17, 'prompt_eval_duration': 282643000, 'eval_count': 85, 'eval_duration': 1457139000}, id='run-35696fae-b2a2-4fa2-adb8-5cd02eb72fe1-0')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|Hello|!| My| name| is| L|La|MA|,| I|'|m| a| large| language| model| trained| by| a| team| of| research|er| at| Meta| A|I|.| My| primary| function| is| to| understand| and| respond| to| human| input| in| a| helpful| and| inform|ative| way|.| I| can| answer| questions|,| provide| information|,| and| even| generate| text| based| on| a| given| prompt|.| I| am| constantly| learning| and| impro|ving| my| ab|ilities|,| so| please| bear| with| me| if| I| make| any| mistakes| or| don|'|t| fully| understand| your| question| at| times|.| I|'|m| here| to| help| and| provide| assistance| in| any| way| I| can|!||"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "async for chunk in llm.astream(\"hello. tell me something about yourself\"):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow import ConsultCodellama\n",
    "consult_code_llama = ConsultCodellama().get_runnable() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow import ConsultCodellama\n",
    "consult_code_llama = ConsultCodellama().get_runnable() \n",
    "async for chunk in consult_code_llama.astream({\"code_snippet\": \"print('hello world')\"}):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = consult_code_llama.invoke({\"code_snippet\": \"print('hello world')\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'feedback': ''}\n",
      "{'feedback': 'The'}\n",
      "{'feedback': 'The code'}\n",
      "{'feedback': 'The code snippet'}\n",
      "{'feedback': 'The code snippet provided'}\n",
      "{'feedback': 'The code snippet provided is'}\n",
      "{'feedback': 'The code snippet provided is a'}\n",
      "{'feedback': 'The code snippet provided is a simple'}\n",
      "{'feedback': 'The code snippet provided is a simple print'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement.'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review.'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review. The'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review. The only'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review. The only feedback'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review. The only feedback I'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review. The only feedback I can'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review. The only feedback I can provide'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review. The only feedback I can provide is'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review. The only feedback I can provide is that'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review. The only feedback I can provide is that the'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review. The only feedback I can provide is that the code'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review. The only feedback I can provide is that the code is'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review. The only feedback I can provide is that the code is well'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review. The only feedback I can provide is that the code is well-'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review. The only feedback I can provide is that the code is well-form'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review. The only feedback I can provide is that the code is well-formatted'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review. The only feedback I can provide is that the code is well-formatted and'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review. The only feedback I can provide is that the code is well-formatted and easy'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review. The only feedback I can provide is that the code is well-formatted and easy to'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review. The only feedback I can provide is that the code is well-formatted and easy to read'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review. The only feedback I can provide is that the code is well-formatted and easy to read.'}\n",
      "{'feedback': 'The code snippet provided is a simple print statement. It does not contain any complex logic or functionality that would require a detailed review. The only feedback I can provide is that the code is well-formatted and easy to read.', 'score': 6}\n"
     ]
    }
   ],
   "source": [
    "async for chunk in consult_code_llama.astream({\"code_snippet\": \"print('hello world')\"}):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      +-------------+      \n",
      "      | PromptInput |      \n",
      "      +-------------+      \n",
      "             *             \n",
      "             *             \n",
      "             *             \n",
      "  +--------------------+   \n",
      "  | ChatPromptTemplate |   \n",
      "  +--------------------+   \n",
      "             *             \n",
      "             *             \n",
      "             *             \n",
      "      +------------+       \n",
      "      | ChatOllama |       \n",
      "      +------------+       \n",
      "             *             \n",
      "             *             \n",
      "             *             \n",
      "   +------------------+    \n",
      "   | JsonOutputParser |    \n",
      "   +------------------+    \n",
      "             *             \n",
      "             *             \n",
      "             *             \n",
      "+------------------------+ \n",
      "| JsonOutputParserOutput | \n",
      "+------------------------+ \n"
     ]
    }
   ],
   "source": [
    "consult_code_llama.get_graph().print_ascii()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consult_code_llama.get_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_html_renderable(str):\n",
    "    try: \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"%%{init: {'flowchart': {'curve': 'linear'}}}%%\\ngraph TD;\\n\\tPromptInput[PromptInput]:::startclass;\\n\\tChatPromptTemplate([ChatPromptTemplate]):::otherclass;\\n\\tChatOllama([ChatOllama]):::otherclass;\\n\\tJsonOutputParser([JsonOutputParser]):::otherclass;\\n\\tJsonOutputParserOutput[JsonOutputParserOutput]:::endclass;\\n\\tPromptInput --> ChatPromptTemplate;\\n\\tChatPromptTemplate --> ChatOllama;\\n\\tJsonOutputParser --> JsonOutputParserOutput;\\n\\tChatOllama --> JsonOutputParser;\\n\\tclassDef startclass fill:#ffdfba;\\n\\tclassDef endclass fill:#baffc9;\\n\\tclassDef otherclass fill:#fad7de;\\n\""
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mermaid = consult_code_llama.get_graph().draw_mermaid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "%%{init: {'flowchart': {'curve': 'linear'}}}%%\n",
    "graph TD;\n",
    "    PromptInput[PromptInput]:::startclass;\n",
    "    ChatPromptTemplate([ChatPromptTemplate]):::otherclass;\n",
    "    ChatOllama([ChatOllama]):::otherclass;\n",
    "    JsonOutputParser([JsonOutputParser]):::otherclass;\n",
    "    JsonOutputParserOutput[JsonOutputParserOutput]:::endclass;\n",
    "    PromptInput --> ChatPromptTemplate;\n",
    "    ChatPromptTemplate --> ChatOllama;\n",
    "    ChatOllama --> JsonOutputParser;\n",
    "    JsonOutputParser --> JsonOutputParserOutput;\n",
    "    classDef startclass fill:#ffdfba;\n",
    "    classDef endclass fill:#baffc9;\n",
    "    classDef otherclass fill:#fad7de;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (249449593.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[138], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    mermaid =\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "mermaid =  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "from loguru import logger\n",
    "class State:\n",
    "    def __init__(self):\n",
    "        self._state: Dict[str, Any] = {}\n",
    "        logger.info(\"Initialized state management.\")\n",
    "\n",
    "    def set_state(self, key: str, value: Any):\n",
    "        \"\"\"Set the state for a given key.\"\"\"\n",
    "        self._state[key] = value\n",
    "        logger.info(f\"State set: {key} = {value}\")\n",
    "\n",
    "    def get_state(self, key: str) -> Any:\n",
    "        \"\"\"Get the state for a given key.\"\"\"\n",
    "        value = self._state.get(key)\n",
    "        logger.info(f\"State retrieved: {key} = {value}\")\n",
    "        return value\n",
    "\n",
    "    def update_state(self, key: str, value: Any):\n",
    "        \"\"\"Update the state for a given key.\"\"\"\n",
    "        if key in self._state:\n",
    "            logger.info(f\"State updated: {key} = {value}\")\n",
    "            self._state[key] = value\n",
    "        else:\n",
    "            logger.warning(f\"State key not found: {key}\")\n",
    "\n",
    "    def delete_state(self, key: str):\n",
    "        \"\"\"Delete the state for a given key.\"\"\"\n",
    "        if key in self._state:\n",
    "            del self._state[key]\n",
    "            logger.info(f\"State deleted: {key}\")\n",
    "        else:\n",
    "            logger.warning(f\"State key not found: {key}\")\n",
    "\n",
    "    def get_all_states(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get all states.\"\"\"\n",
    "        logger.info(\"All states retrieved.\")\n",
    "        return self._state\n",
    "\n",
    "    def clear_states(self):\n",
    "        \"\"\"Clear all states.\"\"\"\n",
    "        self._state.clear()\n",
    "        logger.info(\"All states cleared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-06 16:35:44.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mInitialized state management.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "global_state = State()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def callback1():\n",
    "    global_state.set_state('callback1', 'Callback 1 executed')\n",
    "    print(\"Callback 1 executed and state updated.\")\n",
    "\n",
    "def callback2():\n",
    "    global_state.set_state('callback2', 'Callback 2 executed')\n",
    "    print(\"Callback 2 executed and state updated.\")\n",
    "\n",
    "def callback3():\n",
    "    global_state.set_state('callback3', 'Callback 3 executed')\n",
    "    print(\"Callback 3 executed and state updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import auto_schema_prompt\n",
    "prompt, parser = auto_schema_prompt(CodeFeedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"message\": {\"description\": \"Comments of the code\", \"title\": \"Message\", \"type\": \"string\"}, \"score\": {\"description\": \"Your rating of the code\\\\n                                  from 0 to 10\", \"title\": \"Score\", \"type\": \"number\"}}, \"required\": [\"message\", \"score\"]}\\n```'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow import Workflow, ConsultCodellama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issubclass(Workflow, ConsultCodellama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "class A(ABC):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(A):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issubclass(B, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-06 15:43:29.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mworkflow_storage\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mFound 2 workflows\u001b[0m\n",
      "\u001b[32m2024-06-06 15:43:29.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mworkflow_storage\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mCreating vector store from workflows\u001b[0m\n",
      "\u001b[32m2024-06-06 15:43:29.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mworkflow_storage\u001b[0m:\u001b[36m_init_vectorstore\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mCreating vector store from documents\u001b[0m\n",
      "\u001b[32m2024-06-06 15:43:35.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mworkflow_storage\u001b[0m:\u001b[36m_init_vectorstore\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mVector store created\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'ConsultCodellama',\n",
       "  'description': 'Consult Codellama for code review.\\n\\n        Codellama is an AI assistant specialized in code review.\\n        It will provide comments and rating on the code snippet.',\n",
       "  'runnable': ChatPromptTemplate(input_variables=['code_snippet'], partial_variables={'output_prompt': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"message\": {\"title\": \"Message\", \"description\": \"Comments of the code\", \"type\": \"string\"}, \"score\": {\"title\": \"Score\", \"description\": \"Your rating of the code\\\\n                                  from 0 to 10\", \"type\": \"number\"}}, \"required\": [\"message\", \"score\"]}\\n```'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a AI assitant\\n                 with expertise in code review.\\n\\n                 You will be given a code snippet and you\\n                 should provide comments and rating on the code')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['code_snippet', 'output_prompt'], template='{code_snippet} \\n {output_prompt}'))])\n",
       "  | ChatOllama(model='codellama')\n",
       "  | JsonOutputParser(pydantic_object=<class 'workflow.ConsultCodellama.__init__.<locals>.CodeFeedback'>)},\n",
       " {'name': 'Magic',\n",
       "  'description': 'Adds 2 to the input',\n",
       "  'runnable': RunnableLambda(add)}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from workflow_storage import WorkflowStorage\n",
    "workflow_storage = WorkflowStorage()\n",
    "workflow_storage.runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'magic_function_input', 'type': 'integer'}\n",
      "{'title': 'magic_function_output', 'type': 'integer'}\n",
      "{'func': <function magic_function at 0x000001DD7FE3AAC0>, 'name': 'magic_function'}\n"
     ]
    }
   ],
   "source": [
    "def magic_function(x: int) -> int:\n",
    "    \"\"\"Magic function that returns the double of the input\"\"\"\n",
    "    return 2*x \n",
    "from langchain_core.runnables import RunnableLambda\n",
    "runnable = RunnableLambda(magic_function)\n",
    "print(runnable.input_schema().schema())\n",
    "print(runnable.output_schema().schema())\n",
    "# print all attribtued of the runnable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "@tool\n",
    "def magic_function(x: int) -> int:\n",
    "    \"\"\"Magic function that returns the double of the input\"\"\"\n",
    "    return 2*x\n",
    "\n",
    "tool_func = magic_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'magic_functionSchema',\n",
       " 'type': 'object',\n",
       " 'properties': {'x': {'title': 'X', 'type': 'integer'}},\n",
       " 'required': ['x']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_func.get_input_schema().schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Coordnator:\n",
    "    class Message(BaseModel):\n",
    "        sender: str = Field(..., description=\"The sender of the message\")\n",
    "        mention: List[str] = Field(..., min_items=1)\n",
    "        message: List[str] = Field(..., )\n",
    "        message_pool: \n",
    "\n",
    "    class State(BaseModel):\n",
    "\n",
    "    class CoordinatorState(BaseModel):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "class MedicalRocordFormEntry(BaseModel):\n",
    "    name: str = Field(..., description=\"Name of the patient\")\n",
    "    age: int = Field(..., description=\"Age of the patient\")\n",
    "    sex: Literal[\"male\", \"female\", \"other\"] = Field(...,\n",
    "        description=\"The sex of the patient\")\n",
    "    height: float = Field(..., description=\"Height of the patient in meters\")\n",
    "    weight: float = Field(..., description=\"Weight of the patient in kilograms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.with_structured_output(MedicalRocordFormEntry)\n",
    "from langchain_core.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_medical_record_entry_valid(record: dict) -> bool:\n",
    "    name = record.get(\"name\", None)\n",
    "    age = record.get(\"age\", None)\n",
    "    sex = record.get(\"sex\", None)\n",
    "    height = record.get(\"height\", None)\n",
    "    weight = record.get(\"weight\", None)\n",
    "    if not all([name, age, sex, height, weight]):\n",
    "        return False\n",
    "    try:\n",
    "        entry = MedicalRocordFormEntry(name=name,\n",
    "                                       age=age,\n",
    "                                       sex=sex,\n",
    "                                        height=height,\n",
    "                                        weight=weight)\n",
    "    except Exception as e:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FormFillerState(BaseModel):\n",
    "    is_valid: bool = False\n",
    "    \n",
    "graph = StateGraph(FormFillerState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_input():\n",
    "    # in jupter notebook, get the user input from the user\n",
    "    user_input = input()\n",
    "    return user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentscope",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
